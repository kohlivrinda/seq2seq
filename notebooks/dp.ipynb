{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader,Dataset, RandomSampler, TensorDataset\n",
    "from opacus.layers.dp_rnn import DPGRU\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_TOKEN = 0\n",
    "EOS_TOKEN = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name # ??? is this the language name\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.word2count = {}\n",
    "        self.n_words = 2\n",
    "        \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2idx:\n",
    "            self.word2idx[word] = self.n_words\n",
    "            self.idx2word[self.n_words] = word\n",
    "            self.word2count[word] = 1\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "            \n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    lines = open(f\"../data/{lang1}-{lang2}.txt\", encoding=\"utf-8\").read().strip().split('\\n')\n",
    "    \n",
    "    pairs = [[normalizeString(s) for s in line.split('\\t')] for line in lines]\n",
    "    \n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang, output_lang = Lang(lang2), Lang(lang1)\n",
    "    else:\n",
    "        input_lang, output_lang = Lang(lang1), Lang(lang2)\n",
    "    return input_lang, output_lang, pairs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(\" \")) < MAX_LENGTH and len(p[1].split(\" \")) < MAX_LENGTH and p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [p for p in pairs if filterPair(p)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count:\n",
      "fra 4601\n",
      "eng 2991\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse = False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    pairs = filterPairs(pairs)\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Word Count:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p = 0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = DPGRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        emb = self.dropout(emb)\n",
    "        output, hidden = self.gru(emb)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = DPGRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward_step(self, x, hidden):\n",
    "        op = self.embedding(x)\n",
    "        op = F.relu(op)\n",
    "        op, hidden = self.gru(op, hidden) # update hidden state\n",
    "        op = self.out(op)\n",
    "        return op, hidden\n",
    "    \n",
    "    def forward(self, enc_outputs, enc_hidden, target_tensor=None):\n",
    "        batch_size = enc_outputs.size(0)\n",
    "        decoder_input = torch.empty((batch_size, 1), dtype=torch.long, device=device).fill_(SOS_TOKEN)\n",
    "        decoder_hidden = enc_hidden\n",
    "        decoder_outputs = []\n",
    "        \n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            \n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "            \n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim = 1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        return decoder_outputs, decoder_hidden, None\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        \n",
    "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Ua = nn.Linear(hidden_size, hidden_size)\n",
    "        self.Va = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, query, keys):\n",
    "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "        weights = F.softmax(scores, dim = -1)\n",
    "        context = torch.bmm(weights, keys)\n",
    "        return context, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p = 0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attn = BahdanauAttention(hidden_size)\n",
    "        self.gru = DPGRU(2*hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "    \n",
    "    def forward_step(self, x, hidden, enc_outputs):\n",
    "        emb = self.dropout(self.embedding(x))\n",
    "        query = hidden.permute(1, 0, 2)\n",
    "        context , attn_weights = self.attn(query, enc_outputs)\n",
    "        input_gru = torch.cat((emb, context), dim=2)\n",
    "        op, hidden = self.gru(input_gru, hidden)\n",
    "        op = self.out(op)\n",
    "        return op, hidden, attn_weights\n",
    "    \n",
    "    def forward(self, enc_outputs, enc_hidden, target_tensor=None):\n",
    "        batch_size = enc_outputs.size(0)\n",
    "        decoder_input = torch.empty((batch_size, 1), dtype=torch.long, device=device).fill_(SOS_TOKEN)\n",
    "        decoder_hidden = enc_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions =[]\n",
    "        \n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, attn_weights = self.forward_step(decoder_input, decoder_hidden, enc_outputs)\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(attn_weights)\n",
    "            \n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "            else:\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "            \n",
    "        decoder_outputs = torch.cat(decoder_outputs, dim = 1)\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim =1)\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        enc_output, enc_hidden = self.encoder(x)\n",
    "        dec_output, _, _ = self.decoder(enc_output, enc_hidden, y)\n",
    "        return dec_output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2idx[word] for word in sentence.split(\" \")]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_TOKEN)\n",
    "    return torch.tensor(indexes, dtype= torch.long, device=device).view(1, -1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "    \n",
    "    n = len(pairs)\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype =np.int32)\n",
    "    target_ids = np.zeros((n,MAX_LENGTH), dtype=np.int32)\n",
    "    \n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids = indexesFromSentence(input_lang, inp)\n",
    "        tgt_ids = indexesFromSentence(output_lang, tgt)\n",
    "        inp_ids.append(EOS_TOKEN)\n",
    "        tgt_ids.append(EOS_TOKEN)\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "        \n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                            torch.LongTensor(target_ids).to(device))\n",
    "    \n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size= batch_size)\n",
    "    return input_lang, output_lang, train_dataloader\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, optimizer, criterion, privacy_engine):\n",
    "    \n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        x, y = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        dec_output = model(x, y)\n",
    "        \n",
    "        loss = criterion(\n",
    "            dec_output.view(-1, dec_output.size(-1)),\n",
    "            y.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, model, n_epochs, privacy_engine, privacy_config, lr=0.001, plot_freq=100, print_freq = 100):\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0\n",
    "    plot_loss_total = 0\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    model, optimizer, train_dataloader = privacy_engine.make_private_with_epsilon(\n",
    "        module = model,\n",
    "        optimizer = optimizer,\n",
    "        data_loader = train_dataloader,\n",
    "        target_epsilon = privacy_config['epsilon'],\n",
    "        target_delta = privacy_config['delta'],\n",
    "        epochs = n_epochs,\n",
    "        max_grad_norm = privacy_config['max_per_sample_grad_norm']\n",
    "    )\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        loss = train_epoch(train_dataloader, model, optimizer, criterion, privacy_engine)\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "        \n",
    "        if epoch % print_freq == 0:\n",
    "            print_loss_avg = print_loss_total / print_freq\n",
    "            print_loss_total = 0\n",
    "            print(f\"Epoch: {epoch} || Progress: {epoch/n_epochs} || Avg Loss: {print_loss_avg}\")\n",
    "            if privacy_engine:\n",
    "                epsilon = privacy_engine.get_epsilon(delta)\n",
    "                print(f\"Epsilon: {epsilon}\")\n",
    "        \n",
    "        \n",
    "        if epoch % plot_freq == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_freq\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "            \n",
    "    showPlot(plot_losses)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, attn = decoder(encoder_outputs, encoder_hidden)\n",
    "        \n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoder_ids = topi.squeeze()\n",
    "        \n",
    "        decoded_words = []\n",
    "        for idx in decoder_ids:\n",
    "            if idx.item() == EOS_TOKEN:\n",
    "                decoded_words.append('<EOS')\n",
    "                break\n",
    "            decoded_words.append(output_lang.idx2word[idx.item()])\n",
    "        return decoded_words, attn\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_config = {\n",
    "    \"delta\" : 8e-5,\n",
    "    \"max_per_sample_grad_norm\" : 1.5,\n",
    "    \"epsilon\" : 12.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count:\n",
      "fra 4601\n",
      "eng 2991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vri/miniconda3/envs/torch_env/lib/python3.11/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "/home/vri/miniconda3/envs/torch_env/lib/python3.11/site-packages/opacus/accountants/analysis/rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "/home/vri/miniconda3/envs/torch_env/lib/python3.11/site-packages/torch/nn/modules/module.py:1827: FutureWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  self._maybe_warn_non_full_backward_hook(args, result, grad_fn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 || Progress: 0.0625 || Avg Loss: 2.9006292742723856\n",
      "Epsilon: 3.6108045871158283\n",
      "Epoch: 10 || Progress: 0.125 || Avg Loss: 2.3274709098165927\n",
      "Epsilon: 4.563770762393464\n",
      "Epoch: 15 || Progress: 0.1875 || Avg Loss: 2.2402928175206958\n",
      "Epsilon: 5.342637890991645\n",
      "Epoch: 20 || Progress: 0.25 || Avg Loss: 2.1901635221928855\n",
      "Epsilon: 6.0311851317320855\n",
      "Epoch: 25 || Progress: 0.3125 || Avg Loss: 2.11118973014075\n",
      "Epsilon: 6.661040942877242\n",
      "Epoch: 30 || Progress: 0.375 || Avg Loss: 2.0477432632579484\n",
      "Epsilon: 7.248506637355471\n",
      "Epoch: 35 || Progress: 0.4375 || Avg Loss: 2.0016304734032913\n",
      "Epsilon: 7.803421014259308\n",
      "Epoch: 40 || Progress: 0.5 || Avg Loss: 1.9634446409827504\n",
      "Epsilon: 8.332257081226423\n",
      "Epoch: 45 || Progress: 0.5625 || Avg Loss: 1.9472569720705128\n",
      "Epsilon: 8.839589254811067\n",
      "Epoch: 50 || Progress: 0.625 || Avg Loss: 1.9302881639096992\n",
      "Epsilon: 9.328751589779765\n",
      "Epoch: 55 || Progress: 0.6875 || Avg Loss: 1.9192318533385933\n",
      "Epsilon: 9.802306326436696\n",
      "Epoch: 60 || Progress: 0.75 || Avg Loss: 1.9083007724591474\n",
      "Epsilon: 10.262252423029643\n",
      "Epoch: 65 || Progress: 0.8125 || Avg Loss: 1.9069990659559237\n",
      "Epsilon: 10.710195500100324\n",
      "Epoch: 70 || Progress: 0.875 || Avg Loss: 1.8942800110278846\n",
      "Epsilon: 11.147438764480096\n",
      "Epoch: 75 || Progress: 0.9375 || Avg Loss: 1.896518468190838\n",
      "Epsilon: 11.575067758404726\n",
      "Epoch: 80 || Progress: 1.0 || Avg Loss: 1.8879541564920097\n",
      "Epsilon: 11.994004773408037\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "input_lang, output_lang, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = Encoder(input_lang.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
    "model = Seq2Seq(encoder, decoder)\n",
    "\n",
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "train(train_dataloader, model, 80, privacy_engine, privacy_config, print_freq=5, plot_freq=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
